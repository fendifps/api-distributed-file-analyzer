# API Distributed File Analyzer

![Architecture](https://img.shields.io/badge/Architecture-Microservices-blue)
![Python](https://img.shields.io/badge/Python-3.11-green)
![Node](https://img.shields.io/badge/Node-20-green)
![Docker](https://img.shields.io/badge/Docker-Compose-blue)

**Proyecto de portafolio** que demuestra arquitectura de microservicios profesional con procesamiento distribuido de archivos.

## ğŸ¯ Objetivo del Proyecto

Este proyecto es una **demostraciÃ³n tÃ©cnica** diseÃ±ada para mostrar:
- Arquitectura de microservicios escalable
- Procesamiento asÃ­ncrono con colas
- IntegraciÃ³n de mÃºltiples tecnologÃ­as backend
- Buenas prÃ¡cticas de desarrollo y documentaciÃ³n

**No es un producto final**, sino un showcase de habilidades backend.

---

## ğŸ—ï¸ Arquitectura

```
Cliente HTTP
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Gateway Service (Node.js/Express)  â”‚
â”‚  - AutenticaciÃ³n JWT                â”‚
â”‚  - Rate Limiting                    â”‚
â”‚  - API Gateway                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Analyzer Service (Python/FastAPI)   â”‚
â”‚  - Procesamiento de archivos        â”‚
â”‚  - GestiÃ³n de tareas                â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redis  â”‚          â”‚PostgreSQLâ”‚
â”‚  Queue  â”‚          â”‚   DB     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“                      â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  Worker â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ Process â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚ MongoDB  â”‚
                     â”‚   Logs   â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ver:** [architecture-diagram.md](./architecture-diagram.md) para detalles completos.

---

## ğŸ› ï¸ Stack TecnolÃ³gico

### Gateway Service (Puerto 3000)
- **Node.js 20** + Express.js
- **JWT** para autenticaciÃ³n
- **Redis** para rate limiting
- **PostgreSQL** para usuarios

### Analyzer Service (Puerto 8000)
- **Python 3.11** + FastAPI
- **Redis Queue (RQ)** para procesamiento asÃ­ncrono
- **PostgreSQL** para tareas y resultados
- **MongoDB** para logs y auditorÃ­a
- **OpenAPI/Swagger** documentaciÃ³n automÃ¡tica

### Infraestructura
- **Docker** y **Docker Compose**
- **PostgreSQL 15**
- **MongoDB 7**
- **Redis 7**

---

## ğŸš€ CÃ³mo Levantar el Proyecto

### Prerrequisitos
- Docker y Docker Compose instalados
- Puertos disponibles: 3000, 8000, 5432, 27017, 6379

### Pasos

1. **Clonar el repositorio**
```bash
git clone https://github.com/tu-usuario/api-distributed-file-analyzer.git
cd api-distributed-file-analyzer
```

2. **Configurar variables de entorno**
```bash
cp .env.example .env
# Editar .env si es necesario (valores por defecto funcionan)
```

3. **Levantar todos los servicios**
```bash
docker-compose up --build
```

4. **Esperar a que todo estÃ© listo** (~30 segundos)
```
âœ“ PostgreSQL ready
âœ“ MongoDB ready
âœ“ Redis ready
âœ“ Gateway Service running on port 3000
âœ“ Analyzer Service running on port 8000
âœ“ Worker process started
```

5. **Acceder a la documentaciÃ³n**
- Gateway API: http://localhost:3000/health
- Analyzer API: http://localhost:8000/docs (Swagger UI)
- OpenAPI Schema: http://localhost:8000/openapi.json

---

## ğŸ“¡ Endpoints y Flujo de Uso

### 1. Registro de Usuario
```bash
POST http://localhost:3000/api/auth/register
Content-Type: application/json

{
  "email": "user@example.com",
  "password": "securepass123",
  "name": "John Doe"
}

# Response: 201 Created
{
  "message": "User registered successfully",
  "userId": "uuid-here"
}
```

### 2. Login
```bash
POST http://localhost:3000/api/auth/login
Content-Type: application/json

{
  "email": "user@example.com",
  "password": "securepass123"
}

# Response: 200 OK
{
  "token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "user": {
    "id": "uuid",
    "email": "user@example.com",
    "name": "John Doe"
  }
}
```

### 3. Subir Archivo para AnÃ¡lisis
```bash
POST http://localhost:3000/api/analyzer/upload
Authorization: Bearer YOUR_JWT_TOKEN
Content-Type: multipart/form-data

file: [tu_archivo.txt/csv/json]

# Response: 202 Accepted
{
  "taskId": "task-uuid",
  "status": "queued",
  "message": "File uploaded and queued for processing"
}
```

### 4. Consultar Estado de Tarea
```bash
GET http://localhost:3000/api/analyzer/tasks/{taskId}
Authorization: Bearer YOUR_JWT_TOKEN

# Response mientras procesa: 200 OK
{
  "taskId": "task-uuid",
  "status": "processing",
  "filename": "archivo.txt",
  "createdAt": "2025-01-15T10:30:00Z"
}

# Response cuando termina: 200 OK
{
  "taskId": "task-uuid",
  "status": "completed",
  "filename": "archivo.txt",
  "result": {
    "fileSize": 1024,
    "lineCount": 42,
    "wordCount": 256,
    "characterCount": 1024,
    "processingTime": "2.3s"
  },
  "createdAt": "2025-01-15T10:30:00Z",
  "completedAt": "2025-01-15T10:30:02Z"
}
```

### 5. Listar Todas las Tareas del Usuario
```bash
GET http://localhost:3000/api/analyzer/tasks
Authorization: Bearer YOUR_JWT_TOKEN

# Response: 200 OK
{
  "tasks": [
    {
      "taskId": "uuid-1",
      "status": "completed",
      "filename": "file1.txt",
      "createdAt": "..."
    },
    {
      "taskId": "uuid-2",
      "status": "processing",
      "filename": "file2.csv",
      "createdAt": "..."
    }
  ]
}
```

---

## ğŸ§ª Testing con cURL

```bash
# 1. Registrar usuario
curl -X POST http://localhost:3000/api/auth/register \
  -H "Content-Type: application/json" \
  -d '{"email":"test@test.com","password":"test123","name":"Test User"}'

# 2. Login
TOKEN=$(curl -X POST http://localhost:3000/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email":"test@test.com","password":"test123"}' \
  | jq -r '.token')

# 3. Subir archivo
TASK_ID=$(curl -X POST http://localhost:3000/api/analyzer/upload \
  -H "Authorization: Bearer $TOKEN" \
  -F "file=@test.txt" \
  | jq -r '.taskId')

# 4. Consultar estado
curl http://localhost:3000/api/analyzer/tasks/$TASK_ID \
  -H "Authorization: Bearer $TOKEN"
```

---

## ğŸ” CaracterÃ­sticas TÃ©cnicas Destacadas

### Seguridad
- âœ… AutenticaciÃ³n JWT con expiraciÃ³n
- âœ… Passwords hasheados con bcrypt
- âœ… Rate limiting por IP (100 req/15min)
- âœ… ValidaciÃ³n de tokens en cada request

### Escalabilidad
- âœ… Procesamiento asÃ­ncrono con Redis Queue
- âœ… Workers escalables independientes
- âœ… Microservicios desacoplados
- âœ… Bases de datos separadas por funciÃ³n

### Observabilidad
- âœ… Logs estructurados en MongoDB
- âœ… Timestamps en todas las operaciones
- âœ… Estados de tareas rastreables
- âœ… AuditorÃ­a de eventos

### Buenas PrÃ¡cticas
- âœ… CÃ³digo organizado por capas (routes/controllers/services)
- âœ… Variables de entorno para configuraciÃ³n
- âœ… Manejo centralizado de errores
- âœ… DocumentaciÃ³n OpenAPI automÃ¡tica
- âœ… Docker multi-stage builds
- âœ… Health checks en servicios

---

## ğŸ“‚ Estructura de CÃ³digo

```
gateway-service/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.js              # Entry point
â”‚   â”œâ”€â”€ config/               # Configuraciones (DB, Redis)
â”‚   â”œâ”€â”€ middleware/           # Auth, Rate Limit, Errors
â”‚   â”œâ”€â”€ routes/               # DefiniciÃ³n de rutas
â”‚   â”œâ”€â”€ controllers/          # LÃ³gica de negocio
â”‚   â”œâ”€â”€ models/               # Modelos de datos
â”‚   â””â”€â”€ utils/                # Helpers (JWT, etc)

analyzer-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py               # Entry point FastAPI
â”‚   â”œâ”€â”€ config.py             # ConfiguraciÃ³n centralizada
â”‚   â”œâ”€â”€ database.py           # Conexiones DB
â”‚   â”œâ”€â”€ models/               # Modelos SQLAlchemy y Pydantic
â”‚   â”œâ”€â”€ routes/               # Routers FastAPI
â”‚   â”œâ”€â”€ services/             # LÃ³gica de negocio
â”‚   â””â”€â”€ workers/              # Worker de procesamiento
```

---

## ğŸ“ Uso como Proyecto de Portafolio

### Para Presentarlo
1. **En tu CV/LinkedIn:**
   - "Sistema de microservicios con procesamiento distribuido"
   - "API RESTful con autenticaciÃ³n JWT y colas asÃ­ncronas"
   
2. **En entrevistas:**
   - Explica la arquitectura y por quÃ© elegiste cada tecnologÃ­a
   - Demuestra el flujo completo (registro â†’ upload â†’ worker â†’ resultado)
   - Menciona las decisiones tÃ©cnicas (PostgreSQL vs MongoDB, Redis Queue)

3. **En tu portafolio web:**
   - Link al repositorio GitHub
   - Screenshots de Swagger UI
   - Diagrama de arquitectura
   - MÃ©tricas: "4 servicios, 3 DBs, procesamiento asÃ­ncrono"

### Mejoras Futuras Sugeridas
Para expandir el proyecto puedes agregar:
- [ ] Tests unitarios y de integraciÃ³n (Pytest, Jest)
- [ ] CI/CD con GitHub Actions
- [ ] Monitoring con Prometheus + Grafana
- [ ] Deploy en AWS/GCP con Kubernetes
- [ ] WebSockets para notificaciones en tiempo real
- [ ] Procesamiento de imÃ¡genes con OpenCV
- [ ] CachÃ© con Redis para resultados frecuentes

---

## ğŸ›‘ Detener el Proyecto

```bash
docker-compose down           # Detener servicios
docker-compose down -v        # Detener y eliminar volÃºmenes (limpieza total)
```

---

## ğŸ“ Licencia

MIT License - Este proyecto es open source y de uso educativo.

---

## ğŸ‘¨â€ğŸ’» Autor

**Anthony Romero aka fendifps**
- GitHub: [@fendifps](https://github.com/fendifps)
- LinkedIn: [Anthony Romero](https://www.linkedin.com/in/anthony-romero-32867b309/)
- Portfolio: [arrn](https://arrn-portfolio.netlify.app/)

---

## ğŸ™ Agradecimientos

Proyecto creado como demostraciÃ³n tÃ©cnica para portafolio profesional.

**Stack:** Node.js â€¢ Python â€¢ FastAPI â€¢ Express â€¢ PostgreSQL â€¢ MongoDB â€¢ Redis â€¢ Docker